% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lta.R
\name{lta}
\alias{lta}
\title{Line transect analysis}
\usage{
lta(
  cruz,
  Rg0,
  fit_filters,
  df_settings,
  estimates,
  use_g0 = TRUE,
  ss_correction = 1,
  abund_eff_types = c("S"),
  abund_bft_range = 0:6,
  bootstraps = 0,
  results_file = NULL,
  toplot = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{cruz}{Your \code{cruz} object (produced from \code{LTabundR::process_surveys()}).
Ensure that this \code{cruz} object is filtered only to the years, regions, and sighting conditions
you would like to use for detection function fitting. Filter your \code{cruz} object with
full flexibility using \code{LTabundR::filter_cruz()}. Note that filtering for detection function fitting
is typically less stringent than filtering for downstream steps for abundance estimation,
since as many sightings are included as possible to combat low sample sizes, as
long as sightings were observed using standard methods in an unbiased search pattern,
and as long as you do not expect detectability to vary across years and regions.}

\item{Rg0}{The result of \code{LTabundR::g0_model()}, which is a \code{data.frame} with Relative
trackline detection probabilities, \code{g(0)}, for each species in each Beaufort sea state.
See \code{LTabundR} dataset \code{data(g0_results)} as an example.
If not provided, weighted \code{g(0)} will not be estimated in this function call,
and unless you manually provide \code{g(0)} values within your \code{estimates} input,
\code{g(0)} will be assumed to be 1 and \verb{g(0)_cv} will be assumed to be 0.}

\item{fit_filters}{A named list, with filters and settings pertaining to the data
used to fit a detection function model.
The slots below are recognized, but only \code{spp}, \code{cohort}, and \code{truncation_distance}
are required (i.e., do not have defaults).
\itemize{
\item \code{spp}: A character vector of species codes. Using multiple species codes may be useful
when you have low sample sizes for a cohort of similar species.
\item \code{pool}: A character string, providing a title for this species pool.
If not specified, the species codes used will be concatenated to produce a title automatically.
\item \code{cohort}: The cohort containing these species, provided as a number
indicating which slot in \code{cruz$cohorts} should be referenced.
\item \code{truncation_distance}: The truncation distance to apply during model fitting.
\item \code{other_species}: A character vector with four recognized values:
\itemize{
\item If \code{"apply"} (the default if not specified),
the species code will be changed to \code{"Other"}
for sightings in which the species was in a mixed-species school
but was not the species with the largest percentage of the total school size.
In those cases, the species was not as relevant to the detection
of the school as the other species were, which may bias the detection function.
This creates a factor level for the detection function to use (when \code{"species"} is a covariate)
to distinguish between cue-relevant species that are within the specified pool
and those that are not.
\item The second option for \code{other_species} is \code{"ignore"}, which
does \strong{not} reassign species codes to \code{"Other"}, and ignores whether the species of
interest held the plurality for a mixed species detection.
\item The third option is \code{"remove"}: any species re-assigned to \code{"Other"} will be removed before the detection
function is fit; this can be useful if only a small number of species are re-assigned
to \code{"Other"}, which would then obviate \code{species} as a viable covariate (since the sample
size of all \code{species} levels would be unlikely to exceed
\code{df_settings$covariates_n_per_level} -- see below).
\item The fourth and final option is \code{coerce}, which forces \emph{all} species codes to \code{"Other"}
for the purposes of detection function fitting and abundance estimation. This can be
useful if you want to toggle the use of \code{species} as a covariate for a specific species pool,
and/or produce abundance estimates for unidentified taxa (e.g., an 'Unidentified dolphins' species pool that includes multiple species codes).
}
}}

\item{df_settings}{A named list, with parameters for fitting the detection function.
The following slots are recognized, but none is required (i.e., all have defaults):
\itemize{
\item \code{covariates}: Covariates you wish to include as candidates in detection function models,
provided as a character vector. The covariates must match columns existing
within \verb{cruz$cohorts$<cohort_name>$sightings}.
Common covariates that you will find within \code{sightings}
include \code{c('Bft','LnSsTot','Cruise','Year','Ship','species')}.
Note that the function will ignore case, coercing all covariates to lowercase.
If \code{LnSsTot} is included as a covariate, the function will (1) check to see if
the \code{sightings} dataframe has a column named \code{ss_valid} (all \code{cruz} objects do),
then, if so, (2) filter \code{sightings} only to rows where \code{ss_valid} is \code{TRUE}, meaning
the school size estimate for that sighting is a valid estimate.
\item \code{covariates_factor}: A Boolean vector, which must be the same length as \code{covariates},
indicating whether each covariate should be treated as a factor instead of a numeric.
\item \code{covariates_levels}: The minimum number of levels a factor covariate must have
in order to be included as an eligible covariate.
\item \code{covariates_n_per_level}: The minimum number of observations within each level of a factor covariate.
If this condition is not met, the covariate is excluded from the candidates.
\item \code{simplify_cue} A Boolean, with default \code{TRUE}, indicating whether or not
\code{cue} codes should be simplified before being included as a covariate in detection function fitting.
This can help to overcome the factor sample size limitations that may prevent
inclusion as a covariate.
If \code{TRUE}, cues 0, 1, 2, 4, and 7 are coerced to 5, representing 'other' cues.
\item \code{simplify_bino} A Boolean, with default \code{TRUE}, indicating whether or not
sighting \code{method} codes should be simplified before being included as a covariate in detection function fitting.
This can help to overcome the factor sample size limitations that may prevent
inclusion as a covariate.
If \code{TRUE}, methods other than 4 are all coerced to 5, representing 'other' methods.
\item \code{detection_function_base}: The base key for the detection function, provided as a character vector.
Accepted values are \code{"hn"} (half-normal key, the default, which exhibit greater stability
when fitting to cetacean survey data; Gerrogette and Forcada 2005), \code{"hr"} (hazard-rate),
or \verb{c("hn", "hr)}, which will loop through both keys and attempt model fitting.
\item \code{base_model}: The initial model formula, upon which to build using candidate covariates.
if not provided by the user, the default is \code{"~ 1"}.
\item \code{delta_aic}: The AICc difference between the model yielding the lowest AICc and
other candidate models, used to define the best-fitting models. Typically,
AICc differences of less than 2 (the default) indicate effectively equal model performance.
If this value is not zero, then model averaging will be done: if multiple models
are within \code{delta_aic} of the model with the lowest AICc, all "best" models will be used
in subsequent steps and their results will be averaged. See \code{Details} below.
}}

\item{estimates}{A nested list (i.e., a list of sublists), in which each constituent sublist
contains the settings for a single density/abundance estimate.
Check out the \code{LTabundR} function, \code{lta_estimates()}, which facilitates building this \code{estimates} argument.
The slots below are recognized in each constituent sublist,
but not all are required (i.e., some have defaults).
\itemize{
\item \code{spp}: (Required) A character vector of species codes.
If multiple codes are provided, a single density/abundance estimate will be provided
for this pooled group of species.
If  \code{NULL}, the codes in \code{fit_filters$spp} will be used.

\item \code{title}: (Required) A title for this abundance estimate, given as a character vector,
e.g., \code{"Striped dolphin - pelagic"}.
If left blank, the species code(s) will be concatenated to use as a title.
Note that, if \code{spp_method} is \code{'each'}, then \code{title} must be the same length as \code{spp}.

\item \code{years}: (Required) A required numeric vector of years, used to filter data
to include only effort/sightings from these years.

\item \code{regions}: (Required) A character vector of geostratum names, used to filter the data
to a study area in which to estimate density/abundance.
Any segment or sighting occurring within \emph{any} of the provided \code{regions} will be returned.
This holds true for nested regions: for example, in analyses from the
Central North Pacific, in which the Hawaii EEZ geostratum (\code{"HI_EEZ"})
is nested within the larger geostratum representing the entire CNP study area (\code{"OtherCNP"}),
an input of \code{regions = "OtherCNP"} will return segments/sightings
\emph{both} inside the Hawaii EEZ \emph{and} outside of it.
These geostratum names must have been used to process this \code{cruz} object cohort during \code{LTabundR::process_surveys()}.
\item \code{cruises}: (An optional numeric vector of cruise numbers, used to filter data to include
effort/sighting from only certain cruises. Ignored if \code{NULL}.

\item \code{regions_remove}: An optional character vector of geostratum names, similar to above.
These regions will be subtracted from \code{regions} to determine the final study area
in which density/abundance will be estimated.
Any segment or sighting occurring within any of these \code{regions_remove} will \strong{not} be
used in density/abundance estimation.
Using the example above, if \code{regions = "OtherCNP"} and \code{regions_remove = "HI_EEZ"},
only segments occuring within \code{OtherCNP} \emph{and} outside of \code{HI-EEZ} will be used.
This can be particularly useful for abundance estimates for pelagic stock that exclude nested insular stocks.
These geostratum names must have been used to process this \code{cruz} object cohort during \code{LTabundR::process_surveys()}.

\item \code{region_title}: An optional character vector indicating the title you would like to
give to the region pertaining to this estimate. This can be useful if you have a
complicated assemblage of regions you are combining and/or removing.  If not supplied,
the function will automatically generate a \code{region_title} based on \code{regions} and \code{regions_remove}.

\item \code{g0}: (Optional) If left as the default \code{NULL}, this function will automatically
estimate the weighted trackline detection probability (\code{g0}) according to the
distribution of Beaufort sea states contained within the survey years/regions for which
density/abundance is being estimated (this is done using the \code{LTabundR} function \code{g0_weighted()};
see its documentation for details). This will only be done if the \code{Rg0} input above is not \code{NULL};
if it is and you do not provide \code{g(0)} values here, \code{g0} will be coerced to equal 1.
To coerce \code{g(0)} to a certain value of your own choosing,
you can provide a numeric vector of length 1 or 2.
If length 1, this value represents \code{g(0)} for all schools regardless of size.
If length 2, these values represent \code{g(0)} for small and large school sizes, as defined by
\code{g0_threshold} below.

\item \code{g0_cv}: (Optional) Similar to \code{g0} above: if left \code{NULL}, the CV of the \code{g(0)} estimate
will be automatically estimated based on weighted survey conditions.
Alternatively, you can manually specify a CV here, using a numeric vector of length 1 or 2.
If you do not specify a value and \code{Rg0} input is \code{NULL}, \code{g0_cv} will be coerced to equal 0.

\item \code{g0_threshold}: (Optional) The school size threshold between small and large groups.

\item \code{alt_g0_spp}: (Optional) An alternate species code to use to draw Relative \code{g(0)} values from
the \code{Rg0} input. This is useful in the event that \code{Rg(0)} was not estimated for the
species whose density/abundance you are estimating, but there \emph{is} a similarly detectable
species whose \code{Rg(0)} parameters have been estimated.

\item \code{combine_g0}: (Optional) A Boolean, with default \code{FALSE}. If \code{TRUE}, weighted g0 estimates will be
produced \emph{separately} for each species code provided (specifically, for each unique row in the
\code{Rg0} table that is found after filtering by the species codes you provide in
this estimate), \emph{THEN} average those estimates together. This can be useful
when you do not have a \code{Rg(0)} estimates for a certain species, but you can approximate
Rg0 by averaging together estimtes from multiple species (e.g., averaging together
weighted g(0) from across rorqual species in order to get a weighted g(0) estimate
for 'Unidentified rorquals').

\item \code{forced_effort} (Optional) If this is a single numeric value instead of \code{NULL} (\code{NULL} is the default),
this value will be used as the survey effort, in km, in a brute-force method.
If left \code{NULL}, the function will calculate survey effort itself.
This is only helpful if you are looking for a relatively easy way to compare results
from your own analysis to another
(e.g., comparing \code{LTabundR} results to reports from NOAA reports prior to 2021,
in which effort was calculated slightly differently).

\item \code{area}: (Optional) If this is a single numeric value instead of \code{NULL} (\code{NULL} is the default),
this value will be used as the area of the region in which abundance is being estimated,
in square km, in a brute-force approach. If left \code{NULL}, the function will calculate
the final area of the survey area resulting from the \code{regions} and \code{regions_remove} filters above.

\item \code{remove_land}: (Optional) A Boolean, with default \code{TRUE}, indicating whether or not land area should
be removed from the survey area before calculating its area for abundance estimation.
This term is only referenced if \code{area} is not specified manually.
}}

\item{use_g0}{A Boolean, with default \code{TRUE}, indicating whether or not to use custom \code{g(0)} value(s).
If \code{FALSE}, the assumed \code{g(0)} value will be 1. This can be a handy way of toggling weighted \code{g(0)}
estimation on and off across all sublists within \code{estimates}.}

\item{ss_correction}{Should a correction be applied to school sizes?
School sizes will be scaled by this number. The default, \code{1}, means no changes will occur.
This is a vestige of pre-2021 analysis workflows, and typically will not be invoked.}

\item{abund_eff_types}{A character vector of \code{EffType} accepted as systematic effort
(for density / abundance estimation). The default is just \code{"S"} (systematic effort),
but in some surveys/cases you may wish to use fine-scale effort (\code{"F"}) too.}

\item{abund_bft_range}{A numeric vector of Beaufort Sea Sates accepted as systematic effort
(for density / abundance estimation). The default is \code{0:6}.}

\item{bootstraps}{The number of bootstrap iterations. If 0 or 1, no bootstrapping will be carried out.}

\item{results_file}{If not \code{NULL}, this input will be taken as the name of the file
in which to save the results as this function works. This can be a handy way of saving
results as you go, in the event of a major error or system crash.}

\item{toplot}{Boolean, with default \code{TRUE}, indicating whether detection function plots (\code{Distance::plot.ds()})
should be displayed as the candidate models are tested.}

\item{verbose}{Boolean, with default \code{TRUE}, indicating whether or not updates should be printed to the Console.}
}
\value{
A named list:
\enumerate{
\item \code{pool}: The species pool this estimate pertains to.
\item \verb{inputs:} A record of the inputs you provided, stored as a list.
\item \code{estimate}: A table of density/abundance estimates for each species/region/year
combination specified in the \code{estimates} input.
This \code{data.frame} contains the following fields:
\enumerate{
\item \code{Region}: Name(s) of geostrata represented in this estimate.
\item \code{Area}: Area of geostratum / region, in square km.
\item \code{year}: Years represented in this estimate.
\item \code{segments}: The number of effort segments used to estimate density/abundance.
\item \code{km}: The km of trackline effort contained in these segments.
\item \code{Area_covered}: The Area surveyed, according to \code{km} and \code{ESW_mean} (see next column).
\item \code{ESW_mean}: Mean effective strip width, in kw, calculated as the mean probability of detection for all detections.
\item \code{n}: The number of detections in the data.
\item \code{g0_est}: The mean \code{g(0)} estimate of detections, which may differ by group due to group size.
\item \code{ER_clusters}: The encounter rate for detections (schools) (\code{n / km})
\item \code{D_clusters}: The density of detections (schools).
\item \code{N_clusters}: The abundance of schools.
\item \code{size_mean}: Average school size.
\item \code{size_sd}: Standard deviation of school size.
\item \code{ER}: Animal encounter rate.
\item \code{D}: Animal density.
\item \code{N}: Animal abundance.
\item \code{g0_small}: the weighted \emph{g(0)} for small group sizes in this estimate.
\item \code{g0_large}: the weighted \emph{g(0)} for large group sizes in this estimate.
\item \code{g0_cv_small}: the CV of weighted \emph{g(0)} for small group sizes in this estimate.
\item \code{g0_cv_large}: the CV of weighted \emph{g(0)} for large group sizes in this estimate.
}

\item \code{df}: A named list with details for the detection function.
\enumerate{
\item \code{best_models}: A \code{data.frame} summary of the best-fitting models,
based upon the table produced by \code{Distance::summarize_ds_models()}.
See that function's documentation for details.
\item \code{all_models}:  Similar to the preceding slot, a tabular summary of \emph{all} models tested.
\item \code{best_objects}:  A list containing the \code{ds} objects (produced by package \code{Distance})
for each of the best-fitting models.
\item \code{sample_size}: A \code{data.frame} with the detections for each species within the species pool
used to fit the detection function (as well as \code{Other} species; see the \code{other_species} input).
\code{Ntot} is total detections for each species; \code{Ndet} is total detections within the truncation distance
and therefore used in the detection function fitting routine; \code{TD} is the truncation distance.
\item \code{curve}: A \code{data.frame} of the best-fitting detection function curve
(best-fitting models averaged together, weighted by AICc), for 100 distances between 0
and the \code{truncation_distance} (two columns: \code{km} and \code{p}, the probability of detection
at that distance).
}

\item \code{g0_tables}: A list with \emph{g(0)} estimation parameters for each sublist in \code{estimates}.

\item \code{bootstrap}: A named list with results from the bootstrap process, only
returned if the \code{bootstraps} input is greater than \code{1}.
\enumerate{
\item \code{summary}: a \code{data.frame} with a row for each species/region/year combination for which density/abundance was estimated.
Notable columns include \code{g0_mean} and \code{g0_cv} (the mean and CV of g(0) values across parametric bootstrap iterations,
which may differ slightly from the non-bootstrapped \code{g0_} estimates provided in the \code{estimate} slot above.);
\code{Nmean} (the mean abundance, based on bootstrap re-sampling);
\code{Nmedian} (median abundance); \code{Nsd} (standard-deviation of abundance);
\code{CV} (coefficient of variation, which applies to both density and abundance);
\code{L95} (the lower BCA 95\% confidence interval), and \code{U95} (the upper BCA 95\% confidence interval).
\item \code{details}: a \code{data.frame} with details for every iteration of the bootstrap routine.
\item \code{df}: a \code{data.frame} with the detection function curve for each bootstrap iteration.
}
}
}
\description{
For a single species or species pool, fit a detection function and estimate density / abundance,
with an option to conduct parametric / non-parametric bootstrap sampling for variance estimation.
}
\details{
See the \href{https://emk-noaa.github.io/LTAvignette/lta.html}{vignette online} for detailed examples & case studies.

\strong{Survey area calculations:}
The area for which abundance is to be estimated is calculated separately for each sublist within \code{estimates}
according to the inpunts \code{regions} and \code{regions_remove}. This calculation is performed by a call to the
\code{LTabundR} function \code{strata_area()}, which handles complex combinations and subtractions of geostrata,
accounting for overlapping strata and the (optional) removal of any land area
(see its documentation for details).
The polygon for each resulting study area is added to the respective \code{estimates} sublist.
Those polygons can be retrieved from the output's \verb{$inputs} slot.

\strong{Weighted g(0) estimates:}
If \code{g(0)} values are not supplied manually for an \code{estimates} sublist, a weighted \code{g(0)}
will be estimated as part of this function's operations through a call to the
\code{LTabundR} function \code{g0_weighted()}, which automatically optimizes a model that
estimates the \code{g(0)} and its CV based on the distribution of effort in different
Beaufort sea states within the specific year, region, and cruise in question.
This is only done if the input \code{Rg0} is supplied.

\strong{Covariates in detection function estimation:} Before detection functions are modelled,
any covariates supplied by the user and specified as a factor are first
tested for eligibility. Only factors with
at least two levels (or whatever you specified with \code{df_settings$covariates_levels})
and 10 observations in each level (or whatever you specified with \code{df_settings$covariates_n_per_level})
are eligible for inclusion.

\strong{Fitting a detection function:} The detection function is estimated using functions
in the package \code{mrds}, primarily the main function \code{mrds::ddf()}, which uses a
Horvitz-Thompson-like estimator to predict the probability of detection for each sighting.
If multiple base key functions (e.g., half-normal or hazard-rate) are provided, and/or if
covariates are specified, model fitting is done in a forward stepwise procedure:
In the first round, the base model (no covariates, i.e., \code{"~1"}) is fit first.
In the second round, each covariate is added one at a time;
at the end of the round, the covariate, if any, that produces the lowest AICc
below the AICc from the previous round is added to the formula.
This process is repeated in subsequent rounds, adding a new covariate term in each round,
until the AICc no longer improves.
If a second base key is provided, the process is repeated for that second key.
All models within \code{delta_aic} of the model with the lowest AICc qualify as best-fitting models.

The best-fitting model(s) is(are) then used to estimate the Effective Strip half-Width (ESW)
based on the covariates associated with each sighting.
If multiple best-fitting models occur, we will find the average ESW for each
sighting across all models, using a weighted mean approach in which we weight according to model AICc.
To turn off this model averaging step, set \code{delta_aic} to \code{0} to avoid passing
multiple models to the abundance estimation stage.

This stage of the \code{lta()} command is executed within a backend function, \code{LTabundR::df_fit()},
which has its own documentation for your reference.

Note that if \code{LnSsTot} and/or \code{Bft} (or any other numeric covariate) are included as
candidate covariates, missing data (in the case of \code{LnSsTot}, rows where \code{ss_valid == FALSE}),
will be removed before detection function fitting, but those sightings will not be removed
from the sightings data used for abundance estimation (see below). (Note that the code to
handle these exceptions are contained within \code{lta()}, not \code{df_fit()}).

\strong{Estimating density & abundance:} Estimates are produced for various combinations
of species, regions, and years, according to the arguments specified in your \code{estimates} list(s).
Before these estimates are produced, we filter the data used to fit the detection function
to strictly systematic (design-based) effort
(as specified in the \code{abund_eff_types} and \code{abund_bft_range} inputs).
Note that if \code{NA}'s occur in the \code{esw} column
(due, for instance, to a covariate with missing data for a sighting),
they will be replaced with the mean \code{esw} value
for the remainder of the dataset in that region-year.
Similarly, if \code{sightings} has a column named \code{ss_valid} (all standard \code{cruz} objects do)
and any of the rows in that column are \code{FALSE}, those rows will have their \code{best}
school size estimate (which will be \code{NA} or \code{1}, since they are invalid) replaced
by the mean best estimate for their respective species.

This stage of the \code{lta()} command is executed within a back-end function, \code{LTabundR::abundance()},
which has its own documentation for your reference.

\strong{Bootstrap variance estimation:} If the \code{bootstraps} input value is greater than 1, bootstrap variance estimation will be attempted.
In each bootstrap iteration, survey segments are re-sampled with replacement
before fitting the detection function and estimating density/abundance.

Note that the entire process is repeated in each bootstrap: step-wise fitting
of the detection function, averaging of the best-fitting models, and density/abundance
estimation for all species/region/year combinations specified in your \code{estimates} input.
At the end of the bootstrap process, results are summarized for each species/region/year combination.
95\% confidence intervals are calculated using the BCA method (package \code{coxed}, function \code{bca()}).

\strong{\code{g(0)} values during bootstrapping:} When conducting the non-parametric bootstrap routine
to estimate the CV of density and abundance, uncertainty is incorporated into the g(0) value
in each iteration using a parametric bootstrapping subroutine:
First, a logit-transformed distribution is modeled
based upon the mean and CV of g(0) provided by the user in the \code{estimates} input
(see documentation for \code{LTabundR::g0_optimize()} for details on this step).
This modeled distribution is used to randomly draw a g(0) value for each iteration
of the density/abundance bootstrap routine. In this way,
the uncertainty in g(0) is propagated into uncertainty in density/abundance.

\strong{Workflow recommendations:} This function was designed to optimize workflow where possible.
Some considerations:
\itemize{
\item Expect a single \code{lta()} call for each species pool. You can use a single call
to estimate the detection function once, then predict density/abundance separately for each species within the pool.
\item Some inputs will be common across all species pools (e.g., \code{df_settings} and \code{bootstraps}).
It may be most efficient -- and easiest to keep consistent and to update --
if you define these common inputs at the top of your script,
then call them with a simple variable in each of your \code{lta()} calls.
\item We recommend setting up each \code{lta()} call starting with \code{bootstraps = 0},
so that you can first test that the simple estimation step is successful for all species pools.
Then test the bootstrapping functionality by setting \code{bootstraps} to \code{10} in each \code{lta()} call.
Track how long it takes for your code to run, which you can use to predict
processing time for a larger number of iterations, e.g., \code{bootstraps = 1000}.
\item The most complicated argument to prepare is \code{estimates}. To help with this,
\code{LTabundR} includes a function, \code{lta_estimates()}. See its documentation for details. }
}
